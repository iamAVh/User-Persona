# ğŸ§  Reddit User Persona Generator

This project generates **realistic and structured user personas** based on a Reddit userâ€™s public activity (comments + posts). It uses **LLM-based summarization** and NLP rule-based heuristics to extract personality, behavior, interests, profession, and more.

Ideal for:
- UX research
- Marketing personas
- LLM fine-tuning or prompt seeding
- Behavioral profiling (educational/experimental use)

---

## ğŸš€ Features

âœ… Scrapes up to 100 comments & 50 posts from a given Reddit username  
âœ… Summarizes user content using Hugging Faceâ€™s `bart-large-cnn-samsum` model  
âœ… Extracts traits like interests, personality, behavior, profession, location  
âœ… Generates professional third-person user persona in text format  
âœ… Outputs formatted text resembling real marketing/user profiles  
âœ… Handles token size issues with safe chunking  
âœ… Fully modular & extendable design

---

## ğŸ§± Project Structure


---

## ğŸ¤– LLM Model Used

- **Model**: [`philschmid/bart-large-cnn-samsum`](https://huggingface.co/philschmid/bart-large-cnn-samsum)  
- **Type**: Transformer-based summarizer (BART architecture)  
- **Token Limit**: 1024  
- **Chunking Logic**: Each text chunk is limited to **â‰¤400 tokens** to avoid overflow

This model was chosen for its strength in conversational and dialogue summarization â€” great for summarizing Reddit content.

---

## ğŸ”§ Tools & Libraries

| Tool / Library               | Purpose                                                  |
|-----------------------------|----------------------------------------------------------|
| `PRAW`                      | Access Reddit user data via API                          |
| `transformers` (HuggingFace) | Load tokenizer & summarization model                    |
| `nltk`                      | Sentence tokenization and text normalization             |
| `re`                        | Regex pattern matching for trait extraction              |
| `os`, `collections`         | File I/O and data structuring                            |

---

## ğŸ¯ How It Works

### 1. **Input**
Provide a Reddit profile URL (e.g., `https://www.reddit.com/user/spez/`) via command line.

### 2. **Reddit Scraping**
- Uses PRAW to extract:
  - 100 latest comments
  - 50 latest posts

### 3. **Preprocessing & Chunking**
- Texts are combined and chunked using tokenizer-aware splitting.
- Each chunk contains â‰¤400 tokens to prevent model overflow.

### 4. **Summarization**
- Each chunk is summarized using `philschmid/bart-large-cnn-samsum`
- Final persona summary is generated by re-summarizing all chunk summaries.

### 5. **Trait Extraction**
Using rule-based NLP and regex:
- **Interests**: Keywords like `gaming`, `music`, `fitness`, etc.
- **Profession**: Matches words like `student`, `developer`, `engineer`, etc.
- **Location**: Regex like `from X`, `based in Y`
- **Personality**: Adjectives like `introvert`, `funny`, etc.
- **Behavior**: Matches emotional or expressive language



---

## ğŸ–¥ï¸ How to Run

```bash
git clone https://github.com/yourusername/reddit-user-persona
cd reddit-user-persona
pip install -r requirements.txt
python main.py


